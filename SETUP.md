# HomeAssist Setup Guide

A modular voice assistant framework featuring wake word detection, real-time transcription, LLM-powered responses, persistent memory, and smart home integration.

---

## üìã Overview

HomeAssist is a privacy-focused voice assistant that runs locally on your machine. It connects to cloud APIs for transcription and AI responses while keeping your conversation data under your control.

### ‚ú® Key Features

- üé§ **Wake Word Detection** ‚Äî Hands-free activation with customizable trigger phrases
- üó£Ô∏è **Real-time Transcription** ‚Äî Low-latency speech-to-text via AssemblyAI
- ü§ñ **LLM Responses** ‚Äî Natural conversation powered by OpenAI's Realtime API
- üß† **Persistent Memory** ‚Äî Remembers user preferences and facts across sessions
- üè† **Smart Home Control** ‚Äî Lights, music, calendar, and more via MCP tools
- ‚ö° **Barge-In Support** ‚Äî Interrupt the assistant mid-speech naturally

---

## üöÄ Installation

### Prerequisites

- Python 3.10+
- macOS (for local TTS) or Linux with audio support
- Microphone and speakers

### Step 1: Clone and Setup

```bash
git clone https://github.com/YOUR_USERNAME/HomeAssistV2.git
cd HomeAssistV2
```

### Step 2: Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment

```bash
cp .env.example .env
```

Edit `.env` with your API keys (see Configuration section below).

### Step 5: Run the Assistant

```bash
# Continuous conversation mode (recommended)
python -m assistant_framework.main_v2 continuous

# Single interaction mode
python -m assistant_framework.main_v2 single
```

> üí° **Tip:** On first run, a configuration summary will print showing which components are active and any missing credentials.

---

## ‚öôÔ∏è Configuration

### Environment Variables

Create a `.env` file in the project root with your API keys.

#### Required Variables

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | OpenAI API key for GPT responses |
| `ASSEMBLYAI_API_KEY` | AssemblyAI key for transcription |

#### Optional ‚Äî AI Services

| Variable | Description |
|----------|-------------|
| `GEMINI_API_KEY` | Google Gemini (for summarization) |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to Google Cloud JSON |

#### Optional ‚Äî Integrations

| Variable | Description |
|----------|-------------|
| `SPOTIFY_CLIENT_ID` | Spotify OAuth client ID |
| `SPOTIFY_CLIENT_SECRET` | Spotify OAuth client secret |
| `SUPABASE_URL` | Supabase project URL |
| `SUPABASE_KEY` | Supabase service role key |
| `CONSOLE_TOKEN` | Dashboard log isolation token |

> ‚ö†Ô∏è **Important:** Never commit your `.env` file to version control!

---

### Config File Reference

All runtime settings live in `assistant_framework/config.py`, organized by feature:

#### Provider Selection

Choose which implementation to use for each component:

```python
TRANSCRIPTION_PROVIDER = "assemblyai"      # Speech-to-text
RESPONSE_PROVIDER = "openai_websocket"     # LLM backend
TTS_PROVIDER = "local_tts"                 # "google_tts" or "local_tts"
WAKEWORD_PROVIDER = "openwakeword"         # Wake word engine
```

#### Wake Word Settings

```python
WAKEWORD_CONFIG = {
    "model_name": "hey_honey",    # Trigger phrase model
    "threshold": 0.2,             # Sensitivity (lower = more sensitive)
    "cooldown_seconds": 2.0,      # Min time between activations
}
```

> üí° **Tip:** Custom wake word models (`.onnx`) go in `audio_data/wake_word_models/`

#### Conversation Flow

```python
TERMINATION_PHRASES = ["over out", "stop listening"]
SEND_PHRASES = ["send it", "sir"]
AUTO_SEND_SILENCE_TIMEOUT = 6.0  # Auto-send after 6s of silence
```

#### Barge-In Detection

Allows interrupting the assistant while it's speaking:

```python
BARGE_IN_CONFIG = {
    "energy_threshold": 0.055,        # Voice detection sensitivity
    "early_barge_in_threshold": 3.0,  # Early interrupts append to previous message
    "min_speech_duration": 0.2,       # Required speech to trigger
}
```

#### Persistent Memory

The assistant remembers facts about you across sessions:

```python
PERSISTENT_MEMORY_CONFIG = {
    "enabled": True,
    "provider": "openai",           # "openai" or "gemini"
    "openai_model": "gpt-5-nano",   # Extraction model
}
```

Memory is stored in `state_management/persistent_memory.json` and includes:

- ‚úÖ User profile (name, location)
- ‚úÖ Known facts ("prefers warm lighting")
- ‚úÖ Behavioral patterns with strength levels

---

## üè† Smart Home Setup

### MCP Server

The MCP (Model Context Protocol) server provides tool capabilities. Configuration is in `mcp_server/config.py`.

#### Kasa Smart Lights

```python
LIGHT_IPS = {
    "morgans_led": "192.168.1.49",
    "living_room_lamp": "192.168.1.165",
}
```

#### Google Calendar

Place credentials in `mcp_server/google_creds/`:

- `google_creds_<user>.json` ‚Äî OAuth client secrets
- `token_<user>.json` ‚Äî Access tokens (auto-generated on first auth)

#### Spotify

Set environment variables and configure users:

```python
SPOTIFY_USERS = {
    "Morgan": {"username": "your_spotify_username"},
}
```

---

## üìä Dashboard Integration

HomeAssist syncs with a remote dashboard for real-time monitoring.

### API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/console/log` | POST/GET | Console logging |
| `/api/sessions` | POST/GET | Manage sessions |
| `/api/messages` | POST | Record messages |
| `/api/tool-calls` | POST | Log tool usage |

### Console Token

The `CONSOLE_TOKEN` isolates data per user/device:

- üîπ Namespaces console logs
- üîπ Filters database records
- üîπ Enables multi-user dashboards

### Data Flow

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     WebSocket      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  HomeAssist     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  AssemblyAI     ‚îÇ
‚îÇ  (Voice Loop)   ‚îÇ                    ‚îÇ  (Transcription)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ REST API
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     Realtime       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Supabase       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Dashboard      ‚îÇ
‚îÇ  (PostgreSQL)   ‚îÇ                    ‚îÇ  (Web UI)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Troubleshooting

### ‚ùå Wake Word Not Detecting

**Symptoms:** Saying the wake phrase doesn't activate the assistant.

**Solutions:**

1. Lower the threshold (more sensitive):

```python
WAKEWORD_CONFIG = {
    "threshold": 0.15,  # Default is 0.2
}
```

2. Check your microphone is not muted

3. Specify the correct input device:

```python
WAKEWORD_CONFIG = {
    "input_device_index": 2,  # Find with: python -m sounddevice
}
```

---

### ‚ùå Barge-In Too Sensitive / Not Working

**Symptoms:** Assistant interrupts on background noise, or won't interrupt at all.

**Solutions:**

Adjust the energy threshold:

```python
BARGE_IN_CONFIG = {
    "energy_threshold": 0.08,   # Higher = less sensitive
    # "energy_threshold": 0.03, # Lower = more sensitive
}
```

---

### ‚ùå Audio Device Conflicts

**Symptoms:** Errors about device busy, or audio cutting out.

**Solutions:**

Increase handoff delay between components:

```python
TURNAROUND_CONFIG = {
    "state_transition_delay": 0.2,  # Default is 0.05
}
```

---

### ‚ùå Memory Not Persisting

**Symptoms:** Assistant forgets information between sessions.

**Solutions:**

1. Verify the file is writable:

```bash
ls -la state_management/persistent_memory.json
```

2. Check API key for memory provider:

```bash
# If using OpenAI for memory extraction
echo $OPENAI_API_KEY

# If using Gemini
echo $GEMINI_API_KEY
```

3. View memory extraction logs ‚Äî look for `üß† Persistent memory updated` in console

---

### ‚ùå Configuration Validation

Run the built-in validator:

```python
from assistant_framework.config import validate_environment, print_config_summary

# Print full config status
print_config_summary()

# Get validation results
results = validate_environment()
print(results)
```

---

## üéØ Advanced Features

### Custom System Prompt

Edit `SYSTEM_PROMPT` in `config.py` to change the assistant's personality:

```python
SYSTEM_PROMPT = """
You're a helpful assistant named Jarvis.
Be formal and precise in your responses.
"""
```

### Pattern-Based Memory

The persistent memory system tracks behavioral patterns with strength levels:

| Strength | Meaning |
|----------|---------|
| `weak` | Speculative, single instance |
| `moderate` | Some supporting evidence |
| `strong` | Clear recurring behavior |
| `confirmed` | Practically a fact |

Patterns upgrade/downgrade based on evidence and inform what gets stored as known facts.

### Latency Tuning

For faster response times, adjust turnaround delays:

```python
TURNAROUND_CONFIG = {
    "state_transition_delay": 0.02,   # Component switches
    "barge_in_resume_delay": 0.02,    # After interruption
    "transcription_stop_delay": 0.1,  # After transcription ends
}
```

> ‚ö†Ô∏è **Warning:** Very low values may cause audio device conflicts on some systems.

---

## üìÅ State Files

| File | Purpose |
|------|---------|
| `state_management/app_state.json` | Runtime state |
| `state_management/conversation_summary.json` | Current session summary |
| `state_management/persistent_memory.json` | Long-term user memory |

---

## üìù License

MIT License ‚Äî See LICENSE file for details.
